{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30656465</td>\n",
       "      <td>\\n\\n      \\n      Koala retrovirus (KoRV) is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28669101</td>\n",
       "      <td>\\n\\n      \\n      Koala (Phascolarctos cinereu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29967444</td>\n",
       "      <td>\\n\\n      \\n      The koala, the only extant s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32470998</td>\n",
       "      <td>\\n\\n      \\n      Habitat destruction and frag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31848216</td>\n",
       "      <td>\\n\\n      \\n      The morphology and locomotor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>33257543</td>\n",
       "      <td>\\n\\n      \\n      Fingerprints are unique to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>36161902</td>\n",
       "      <td>\\n\\n      \\n      Lorises are a group of globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>24906475</td>\n",
       "      <td>\\n\\n      \\n      Structural characterizations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>25197935</td>\n",
       "      <td>\\n\\n      \\n      A specific galactose-binding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>32173180</td>\n",
       "      <td>\\n\\n\\n          Background:\\n        \\n      \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pmid                                           abstract\n",
       "0    30656465  \\n\\n      \\n      Koala retrovirus (KoRV) is a...\n",
       "1    28669101  \\n\\n      \\n      Koala (Phascolarctos cinereu...\n",
       "2    29967444  \\n\\n      \\n      The koala, the only extant s...\n",
       "3    32470998  \\n\\n      \\n      Habitat destruction and frag...\n",
       "4    31848216  \\n\\n      \\n      The morphology and locomotor...\n",
       "..        ...                                                ...\n",
       "923  33257543  \\n\\n      \\n      Fingerprints are unique to p...\n",
       "924  36161902  \\n\\n      \\n      Lorises are a group of globa...\n",
       "925  24906475  \\n\\n      \\n      Structural characterizations...\n",
       "926  25197935  \\n\\n      \\n      A specific galactose-binding...\n",
       "927  32173180  \\n\\n\\n          Background:\\n        \\n      \\...\n",
       "\n",
       "[928 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read abstracts\n",
    "df = pd.read_parquet(\"data/pubmed_dump_raw.parquet\", columns=[\"pmid\", \"abstract\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ent(abstract, ner, min_score):\n",
    "\n",
    "    ner_results = ner(abstract)\n",
    "\n",
    "    if not ner_results:\n",
    "        return {}\n",
    "\n",
    "    entity_df = pd.DataFrame(ner_results)\n",
    "    entity_df = entity_df[entity_df.entity_group != \"MISC\"]\n",
    "    entity_df = entity_df[entity_df.entity_group != \"0\"]\n",
    "    entity_df = entity_df[entity_df.score > min_score]\n",
    "\n",
    "    if entity_df.empty:\n",
    "        return {}\n",
    "    else:\n",
    "        entity_dict = entity_df.groupby(\"entity_group\").word.agg(list).to_dict()\n",
    "        return entity_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 793/928 [16:32<03:53,  1.73s/it]"
     ]
    }
   ],
   "source": [
    "# entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "ent_dict = df.abstract.progress_apply(gen_ent, ner=ner, min_score=0.5)\n",
    "ent_df = pd.DataFrame.from_dict(ent_dict.to_list())\n",
    "df = pd.concat([df, ent_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [20:58<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# entities: DISEASE\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alvaroalon2/biobert_diseases_ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"alvaroalon2/biobert_diseases_ner\"\n",
    ")\n",
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "ent_dict = df.abstract.progress_apply(gen_ent, ner=ner, min_score=0.5)\n",
    "ent_df = pd.DataFrame.from_dict(ent_dict.to_list())\n",
    "df = pd.concat([df, ent_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [22:43<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# entities: GENETIC\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alvaroalon2/biobert_genetic_ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"alvaroalon2/biobert_genetic_ner\"\n",
    ")\n",
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "ent_dict = df.abstract.progress_apply(gen_ent, ner=ner, min_score=0.5)\n",
    "ent_df = pd.DataFrame.from_dict(ent_dict.to_list())\n",
    "df = pd.concat([df, ent_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [19:49<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# entities: CHEMICAL\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alvaroalon2/biobert_chemical_ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"alvaroalon2/biobert_chemical_ner\"\n",
    ")\n",
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "ent_dict = df.abstract.progress_apply(gen_ent, ner=ner, min_score=0.5)\n",
    "ent_df = pd.DataFrame(ent_dict.to_list())\n",
    "df = pd.concat([df, ent_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG\n",
      "PER\n",
      "GENETIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:00<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISEASE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEMICAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Post-process entities\n",
    "def strip_str(instr):\n",
    "    return re.sub(\"[^A-Za-z0-9]+\", \" \", instr)\n",
    "\n",
    "\n",
    "def rm_htkn(row, entity_name):\n",
    "    entities = row[entity_name]\n",
    "    abstract = row[\"abstract\"]\n",
    "\n",
    "    if isinstance(entities, list):\n",
    "        whole_words = []\n",
    "        for word in entities:\n",
    "            word = strip_str(word)\n",
    "            if word != \" \":\n",
    "                if re.search(r\"\\b{}\\b\".format(word), abstract):\n",
    "                    whole_words.append(word)\n",
    "        return whole_words\n",
    "\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "entity_dict = {\n",
    "    \"LOC\": \"location\",\n",
    "    \"ORG\": \"organization\",\n",
    "    \"PER\": \"person\",\n",
    "    \"GENETIC\": \"genetic\",\n",
    "    \"DISEASE\": \"disease\",\n",
    "    \"CHEMICAL\": \"chemical\",\n",
    "}\n",
    "df.abstract = df.abstract.apply(strip_str)\n",
    "for entity in tqdm(entity_dict.keys()):\n",
    "    df[entity] = df.apply(rm_htkn, args=(entity,), axis=1)\n",
    "\n",
    "df = df.rename(columns=entity_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['abstract'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aisli\\Documents\\pbmd\\pbmd\\enrich_ner.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aisli/Documents/pbmd/pbmd/enrich_ner.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Save entities\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aisli/Documents/pbmd/pbmd/enrich_ner.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m s: s\u001b[39m.\u001b[39;49mfillna({i: [] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m df\u001b[39m.\u001b[39;49mindex}))\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mabstract\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aisli/Documents/pbmd/pbmd/enrich_ner.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39mto_parquet(\u001b[39m\"\u001b[39m\u001b[39mdata/entities_05.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aisli\\miniconda3\\envs\\pbmd\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aisli\\miniconda3\\envs\\pbmd\\lib\\site-packages\\pandas\\core\\frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4809\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   4810\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   4811\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4818\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4819\u001b[0m ):\n\u001b[0;32m   4820\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4821\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4822\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4955\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4956\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4957\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   4958\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   4959\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4960\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   4961\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   4962\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   4963\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   4964\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   4965\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aisli\\miniconda3\\envs\\pbmd\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4269\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\aisli\\miniconda3\\envs\\pbmd\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aisli\\miniconda3\\envs\\pbmd\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6660\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6661\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6662\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6663\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['abstract'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Save entities\n",
    "df = df.apply(lambda s: s.fillna({i: [] for i in df.index})).drop(columns=\"abstract\")\n",
    "df.to_parquet(\"data/entities_05.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pbmd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd019aaf1f611e90ac1028bec02a0338950b00eb5434906f3c14a2e122abe040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
